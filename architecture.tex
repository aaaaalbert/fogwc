%!TEX root = paper.tex
\section{System Architecture}

An important insight for Seattle as a platform is how the classical
dichotomy of service platform operators and users gives way to multi-faceted
trust relationships between a large number of mutually-unrelated
stakeholders.
In Seattle, the actual edge-based software installs, core infrastructure
services, clearinghouse operations, platform software builds, and remote
application deployments might be carried out and managed by different
groups of people, potentially untrusted (or even unknown) between groups
and among members of the same group.
% Then why/how do people trust each other in such a system?

This gives rise to a set of components~\cite{Cappos2009},
any of which is useful
by itself, that can be freely combined to implement various
deployment models, from pure peer-to-peer operation up to a
provisioned deployment by a dedicated operator. Furthermore,
new components may be introduced freely to replace or augment
existing ones, as long as the component interfaces are adhered to.
We briefly introduce the default components below.
\albert{And yes, they are widely deployed! See section such-and-such!}

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{figures/arch.pdf}
  \caption{Architecture components of Seattle}
  \label{fig:arch}
\end{figure}


\subsection{Components}

Figure~\ref{fig:arch} overviews Seattle's components and interfaces.
%The components fall into three categories: device software,
%infrastructure, and control.

We first introduce the components running on all devices that
run Seattle.
The core element of computation is a restricted,
performance- and security-isolated Python-based
\textit{Sandbox}~\cite{RepySandbox,li2015fence}.
The sandbox \gls{API} provides
networking, file, threading, etc. functions to
experiments\footnote{
Following Seattle's research and educational background, we
call code that is executed in sandboxes an ``experiment'',
regardless of its actual nature.}.

The \textit{Resource Manager} isolates % chroots, effectively!
sandboxes that run in
parallel, and interfaces with them on behalf of authorized remote
parties to start or stop them, upload and download data, reset
sandboxes, or transfer ownership. (The sandboxes on one
device might all have different authorized users if so desired,
so that one Seattle node can serve multiple experimenters.)

The \textit{Device Manager} % (installer with \texttt{--percentage}, start/stop scripts, uninstaller, softwareupdater): device owner retains control!
is the device owner's interface to enable or disable this Seattle
install, and choose the amount of resources that it may consume.

The \textit{Software Updater} keeps all components of the
device software up to date. This concludes the overview of
device-side Seattle components.
%Other components are run either by experimenters, or
%infra-ops, or how should we say this so that it's exact?
\\

To control the fundamental functions of sandboxes (such as
starting to execute code, or downloading collected data),
an \textit{Experiment Manager} % (seash)
is used. The experiment manager contacts sandboxes through the
resource manager interface programmatically, and provides a
human-usable interface to the experimenter. The experimenter
authenticates against sandboxes by using cryptographic keys.

Every experimenter runs an experiment manager, and possesses
their own set of cryptographic keys. This enables interesting
deployment options (and thus applications):
Two experimenters could choose to mutually authenticate the
other on the sandboxes they control, or swap resources, and
so on; making more sandboxes available to an experiment than
a single experimenter could ever reach.
\\

Seattle's device software and an initial set of cryptographic
keys controlling the sandboxes are shipped in the form of a bundled
installer for the specific platform \gls{OS}.
The \textit{Installer Builder} component is responsible for
packaging the code and public keys.
The installer builder allows experimenters to create their own
custom installers, where they get to choose the public key or keys
that are included in the installer package. Every custom installer
can be referenced through its specific, static \gls{URL}.
Thus, by selecting and installing a specific packaged installer,
device owners can choose which experimenters to grant
access to sandboxes on their devices initially.
\\

%This sums up all of the Seattle components required for a
%self-hosted, infrastructure-less deployment already.

The default Seattle architecture also includes a
\textit{Lookup Service}. This is a generic network-accessible
key/value store that the resource manager and experiment manager
can use to announce and retrieve information about sandboxes.
For instance, a resource manager announces its contact information
(such as its or a NAT forwarder's IP address and port number) under
the public keys of all currently authorized experimenters.
The experiment manager retrieves the contact information by looking up
the experimenter's public key at the lookup service, and then
proceeds to contact every resource manager that hosts sandboxes
that the experimenter can control.

Lastly, Seattle provides a \textit{Clearinghouse} which is a
centralized sandbox-sharing site. As motivated earlier,
sandboxes can be swapped; a clearinghouse can act as a trusted
intermediary on behalf of all registered experimenters, and creates
a large pool of sandboxes without requiring all experimenters to
set up mutual trust relationships amongst each others.
The clearinghouse uses the same resource manager interfaces as the
experiment manager does, and provides a human-usable interface to
experimenters. The clearinghouse implements internal policies
that govern the exact rules for swapping sandboxes between
registered experimenters.

This concludes the overview of Seattle components. Our live deployment
of Seattle includes implementations of all components, including a
clearinghouse that offers free access to an initial set of sandboxes
for all registered experimenters.




\subsection{Deployment Alternatives}
\albert{...in which neither ``deployment'' nor ``alternatives'' are
quite the words I'm looking for.}
\lukas{what about...\\
``The Seattle Universe''\\
``Deployment Flexibility''\\
``Unbound Operations''\\
``A Loosly Coupled Infrastructure''
}

The preceding section implicitly introduced different roles relevant
in the Seattle architecture:
\textit{device owners} control whether and how they participate
in Seattle, so as to provide sandboxes to the platform;
\textit{experimenters} use these sandboxes to run their code
on remote devices;
lastly, there are \textit{operator} roles for various components
of the infrastructure.

Central point: These needn't be the same persons.
limited and clearly-defined trust boundaries.

This enables different deployments (!?) as discussed below.


Home alone: device owner is experimenter is perhaps builder op.
no CH nor lookup.

P2P: perhaps an own installer builder, no CH nor lookup,
oob trust between experimenters (and probably device owners)

Seattle: use all components; most operated by us

Sensibility, Social Compute Cloud: all components, some replaced/modified
and operated by ST

A Big Fun Telco Setup: all components, multiple times. Federated CHs.
No renegade resource swapping here! CHs as obligatory, centralized trust
anchors.
